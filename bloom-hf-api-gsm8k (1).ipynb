{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27616239",
   "metadata": {
    "papermill": {
     "duration": 0.006696,
     "end_time": "2023-02-27T07:03:35.391197",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.384501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3641c3e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.404305Z",
     "iopub.status.busy": "2023-02-27T07:03:35.403857Z",
     "iopub.status.idle": "2023-02-27T07:03:35.423054Z",
     "shell.execute_reply": "2023-02-27T07:03:35.421934Z"
    },
    "papermill": {
     "duration": 0.028657,
     "end_time": "2023-02-27T07:03:35.425458",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.396801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gsm8k-dataset/test.jsonl\n",
      "/kaggle/input/gsm8k-dataset/train.jsonl\n",
      "/kaggle/input/gsm8k-dataset/test_prompts.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3644c4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.438806Z",
     "iopub.status.busy": "2023-02-27T07:03:35.437731Z",
     "iopub.status.idle": "2023-02-27T07:03:35.443288Z",
     "shell.execute_reply": "2023-02-27T07:03:35.442173Z"
    },
    "papermill": {
     "duration": 0.015415,
     "end_time": "2023-02-27T07:03:35.446375",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.430960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4d1ea",
   "metadata": {
    "papermill": {
     "duration": 0.005282,
     "end_time": "2023-02-27T07:03:35.457632",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.452350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d31c40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.471409Z",
     "iopub.status.busy": "2023-02-27T07:03:35.470668Z",
     "iopub.status.idle": "2023-02-27T07:03:35.475039Z",
     "shell.execute_reply": "2023-02-27T07:03:35.474153Z"
    },
    "papermill": {
     "duration": 0.014066,
     "end_time": "2023-02-27T07:03:35.477435",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.463369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e745b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.490808Z",
     "iopub.status.busy": "2023-02-27T07:03:35.490173Z",
     "iopub.status.idle": "2023-02-27T07:03:35.494501Z",
     "shell.execute_reply": "2023-02-27T07:03:35.493410Z"
    },
    "papermill": {
     "duration": 0.013689,
     "end_time": "2023-02-27T07:03:35.496661",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.482972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee37f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.509894Z",
     "iopub.status.busy": "2023-02-27T07:03:35.509243Z",
     "iopub.status.idle": "2023-02-27T07:03:35.514027Z",
     "shell.execute_reply": "2023-02-27T07:03:35.512664Z"
    },
    "papermill": {
     "duration": 0.014633,
     "end_time": "2023-02-27T07:03:35.516855",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.502222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d5cc0",
   "metadata": {
    "papermill": {
     "duration": 0.007265,
     "end_time": "2023-02-27T07:03:35.529810",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.522545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions to run the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654684f",
   "metadata": {
    "papermill": {
     "duration": 0.00567,
     "end_time": "2023-02-27T07:03:35.543838",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.538168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using some functions from supplementary materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1c0c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.557879Z",
     "iopub.status.busy": "2023-02-27T07:03:35.557034Z",
     "iopub.status.idle": "2023-02-27T07:03:35.571797Z",
     "shell.execute_reply": "2023-02-27T07:03:35.570234Z"
    },
    "papermill": {
     "duration": 0.026437,
     "end_time": "2023-02-27T07:03:35.575846",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.549409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "NUMBER_SET = [str(num) for num in range(0, 10)]\n",
    "\n",
    "def _is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "FINAL_ANS = \"answer is \"\n",
    "\n",
    "def clean_ans(ans):\n",
    "    \"\"\"\n",
    "    Extract the number from the answer string\n",
    "    \"\"\"\n",
    "    index = ans.find(\".\")\n",
    "    if index >= 0:\n",
    "        end_index = index + 1\n",
    "        while end_index < len(ans) and ans[end_index] in NUMBER_SET:\n",
    "            end_index += 1\n",
    "        ans = ans[:end_index]\n",
    "    while ans and ans.endswith(\".\"):\n",
    "        ans = ans[:-1]\n",
    "    ans = ans.split(\"=\")[-1].strip()\n",
    "    for c in [\"$\", \",\", \"%\", \"â‚¬\", '\"']:\n",
    "        ans = ans.replace(c, \"\")\n",
    "    parts = ans.split(\" \")\n",
    "    for part in parts:\n",
    "        if _is_float(part):\n",
    "            return part\n",
    "    ans = parts[0]  # default\n",
    "    for part in parts:\n",
    "        if not part.isalpha():  # take the 1st non-alpha token\n",
    "            ans = part\n",
    "            break\n",
    "    while ans and ans[-1].isalpha():\n",
    "        ans = ans[:-1]\n",
    "    return ans.strip()\n",
    "\n",
    "def get_ans(pred):\n",
    "    \"\"\"\n",
    "    Method to get the string with The answer is ...\n",
    "    \"\"\"\n",
    "    text = pred\n",
    "    if text.rfind(FINAL_ANS) >= 0:\n",
    "        pred_ans = text[text.rfind(FINAL_ANS) + len(FINAL_ANS) : len(text)].strip()\n",
    "        return pred_ans\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8425e",
   "metadata": {
    "papermill": {
     "duration": 0.00546,
     "end_time": "2023-02-27T07:03:35.589523",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.584063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create some personal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af187b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.605829Z",
     "iopub.status.busy": "2023-02-27T07:03:35.604950Z",
     "iopub.status.idle": "2023-02-27T07:03:35.611415Z",
     "shell.execute_reply": "2023-02-27T07:03:35.610165Z"
    },
    "papermill": {
     "duration": 0.018343,
     "end_time": "2023-02-27T07:03:35.614915",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.596572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query(payload):\n",
    "    \"\"\"\n",
    "    Function to send queries to HF Bloom model with your params\n",
    "    \n",
    "    Args:\n",
    "    payload (dict): your prompt and params\n",
    "    \n",
    "    Returns:\n",
    "    response (json object): generated text\n",
    "    \"\"\"\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ada042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.631360Z",
     "iopub.status.busy": "2023-02-27T07:03:35.630474Z",
     "iopub.status.idle": "2023-02-27T07:03:35.639464Z",
     "shell.execute_reply": "2023-02-27T07:03:35.638464Z"
    },
    "papermill": {
     "duration": 0.018699,
     "end_time": "2023-02-27T07:03:35.642004",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.623305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    \"\"\"\n",
    "    Function to send queries until you get the answer\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): your prompt\n",
    "    \n",
    "    Returns:\n",
    "    answer (float): numeric answer\n",
    "    current_text (str): generated text without the prompt\n",
    "    \"\"\"\n",
    "    # Delete \\n, otherwise not working\n",
    "    prompt = prompt.replace(\"\\n\", \" \")\n",
    "    # Variable to store the answer\n",
    "    answer = None\n",
    "    # Variable to count the iterations\n",
    "    counter = 0\n",
    "    # Variable to save the current generated text\n",
    "    current_text = prompt\n",
    "    \n",
    "    # Set some limit to generate the answer\n",
    "    while counter < 20:\n",
    "        # Increase counter after another try\n",
    "        counter += 1\n",
    "        \n",
    "        # Write the query\n",
    "        payload = {\"inputs\": current_text}, {\"max_new_tokens\": 128, \"wait_for_model\": True}\n",
    "        \n",
    "        # Send the query and get the generated text\n",
    "        output = query(payload)\n",
    "        try:\n",
    "            generated_text = output[0][\"generated_text\"]\n",
    "        except:\n",
    "            print(\"Tokens are dead.\")\n",
    "            break\n",
    "        \n",
    "        # Cut the prompt from the generated text\n",
    "        new_text = generated_text[len(prompt):]\n",
    "        # Update the current text\n",
    "        current_text = generated_text\n",
    "        \n",
    "        # Extract the answer and check it\n",
    "        answer = clean_ans(get_ans(new_text))\n",
    "        if answer != \"\":\n",
    "            # Stop generation if necessary\n",
    "            break\n",
    "\n",
    "    return answer, current_text[len(prompt):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fd41f",
   "metadata": {
    "papermill": {
     "duration": 0.005231,
     "end_time": "2023-02-27T07:03:35.652768",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.647537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606871d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.666107Z",
     "iopub.status.busy": "2023-02-27T07:03:35.665427Z",
     "iopub.status.idle": "2023-02-27T07:03:35.862130Z",
     "shell.execute_reply": "2023-02-27T07:03:35.861014Z"
    },
    "papermill": {
     "duration": 0.206389,
     "end_time": "2023-02-27T07:03:35.864741",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.658352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/gsm8k-dataset/test_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa255781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.879422Z",
     "iopub.status.busy": "2023-02-27T07:03:35.878382Z",
     "iopub.status.idle": "2023-02-27T07:03:35.910763Z",
     "shell.execute_reply": "2023-02-27T07:03:35.909487Z"
    },
    "papermill": {
     "duration": 0.04203,
     "end_time": "2023-02-27T07:03:35.913526",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.871496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>numeric_answer</th>\n",
       "      <th>CoT_anot1</th>\n",
       "      <th>CoT_anot2</th>\n",
       "      <th>CoT_paths</th>\n",
       "      <th>CoT_directions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janetâ€™s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "      <td>18</td>\n",
       "      <td>Q: There are 15 trees in the grove. Grove work...</td>\n",
       "      <td>Q: Shawn has five toys. For Christmas, he got ...</td>\n",
       "      <td>Q: Betty is saving money for a new wallet whic...</td>\n",
       "      <td>Use mathemathical operations and write step by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "      <td>3</td>\n",
       "      <td>Q: There are 15 trees in the grove. Grove work...</td>\n",
       "      <td>Q: Shawn has five toys. For Christmas, he got ...</td>\n",
       "      <td>Q: Betty is saving money for a new wallet whic...</td>\n",
       "      <td>Use mathemathical operations and write step by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "      <td>70000</td>\n",
       "      <td>Q: There are 15 trees in the grove. Grove work...</td>\n",
       "      <td>Q: Shawn has five toys. For Christmas, he got ...</td>\n",
       "      <td>Q: Betty is saving money for a new wallet whic...</td>\n",
       "      <td>Use mathemathical operations and write step by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Janetâ€™s ducks lay 16 eggs per day. She eats th...   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   \n",
       "2  Josh decides to try flipping a house.  He buys...   \n",
       "\n",
       "                                              answer numeric_answer  \\\n",
       "0  Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...             18   \n",
       "1  It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...              3   \n",
       "2  The cost of the house and repairs came out to ...          70000   \n",
       "\n",
       "                                           CoT_anot1  \\\n",
       "0  Q: There are 15 trees in the grove. Grove work...   \n",
       "1  Q: There are 15 trees in the grove. Grove work...   \n",
       "2  Q: There are 15 trees in the grove. Grove work...   \n",
       "\n",
       "                                           CoT_anot2  \\\n",
       "0  Q: Shawn has five toys. For Christmas, he got ...   \n",
       "1  Q: Shawn has five toys. For Christmas, he got ...   \n",
       "2  Q: Shawn has five toys. For Christmas, he got ...   \n",
       "\n",
       "                                           CoT_paths  \\\n",
       "0  Q: Betty is saving money for a new wallet whic...   \n",
       "1  Q: Betty is saving money for a new wallet whic...   \n",
       "2  Q: Betty is saving money for a new wallet whic...   \n",
       "\n",
       "                                      CoT_directions  \n",
       "0  Use mathemathical operations and write step by...  \n",
       "1  Use mathemathical operations and write step by...  \n",
       "2  Use mathemathical operations and write step by...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e66ce1",
   "metadata": {
    "papermill": {
     "duration": 0.005643,
     "end_time": "2023-02-27T07:03:35.925166",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.919523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Decreasing the size (significantly) of a dataset to boost the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99490109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.939520Z",
     "iopub.status.busy": "2023-02-27T07:03:35.938264Z",
     "iopub.status.idle": "2023-02-27T07:03:35.943932Z",
     "shell.execute_reply": "2023-02-27T07:03:35.942916Z"
    },
    "papermill": {
     "duration": 0.015594,
     "end_time": "2023-02-27T07:03:35.946489",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.930895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7e26e",
   "metadata": {
    "papermill": {
     "duration": 0.005506,
     "end_time": "2023-02-27T07:03:35.957919",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.952413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464a1a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:03:35.971733Z",
     "iopub.status.busy": "2023-02-27T07:03:35.971280Z",
     "iopub.status.idle": "2023-02-27T07:08:24.585510Z",
     "shell.execute_reply": "2023-02-27T07:08:24.584029Z"
    },
    "papermill": {
     "duration": 288.625288,
     "end_time": "2023-02-27T07:08:24.589053",
     "exception": false,
     "start_time": "2023-02-27T07:03:35.963765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n",
      "Tokens are dead.\n"
     ]
    }
   ],
   "source": [
    "# Create lists for numeric answers\n",
    "COT_answer1_list = []\n",
    "COT_answer2_list = []\n",
    "CoT_directions_list = []\n",
    "\n",
    "# Create lists for texts\n",
    "COT_text1 = []\n",
    "COT_text2 = []\n",
    "COT_directions_text = []\n",
    "\n",
    "# Run the loop with generation\n",
    "for i in range(len(df)):\n",
    "    question = df[\"CoT_anot1\"][i]\n",
    "    answer, generated_text = generate_answer(question)\n",
    "    COT_answer1_list.append(answer)\n",
    "    COT_text1.append(generated_text)\n",
    "    \n",
    "    question = df[\"CoT_anot2\"][i]\n",
    "    answer, generated_text = generate_answer(question)\n",
    "    COT_answer2_list.append(answer)\n",
    "    COT_text2.append(generated_text)\n",
    "    \n",
    "    question = df[\"CoT_directions\"][i]\n",
    "    answer, generated_text = generate_answer(question)\n",
    "    CoT_directions_list.append(answer)\n",
    "    COT_directions_text.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae41f508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:08:24.641306Z",
     "iopub.status.busy": "2023-02-27T07:08:24.640856Z",
     "iopub.status.idle": "2023-02-27T07:08:24.653126Z",
     "shell.execute_reply": "2023-02-27T07:08:24.651767Z"
    },
    "papermill": {
     "duration": 0.041212,
     "end_time": "2023-02-27T07:08:24.656193",
     "exception": false,
     "start_time": "2023-02-27T07:08:24.614981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"CoT1 answers\"] = COT_answer1_list\n",
    "df[\"CoT2 answers\"] = COT_answer2_list\n",
    "df[\"Directions answers\"] = CoT_directions_list\n",
    "\n",
    "df[\"CoT1 generated\"] = COT_text1\n",
    "df[\"CoT2 generated\"] = COT_text2\n",
    "df[\"Directions generated\"] = COT_directions_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c988cae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T07:08:24.705439Z",
     "iopub.status.busy": "2023-02-27T07:08:24.704924Z",
     "iopub.status.idle": "2023-02-27T07:08:24.731273Z",
     "shell.execute_reply": "2023-02-27T07:08:24.729108Z"
    },
    "papermill": {
     "duration": 0.055274,
     "end_time": "2023-02-27T07:08:24.735103",
     "exception": false,
     "start_time": "2023-02-27T07:08:24.679829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"GSM8K_100_version1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 300.626192,
   "end_time": "2023-02-27T07:08:25.482461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-27T07:03:24.856269",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
